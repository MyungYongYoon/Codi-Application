{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toy_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLxpDaEIaJ8j"
      },
      "source": [
        "Drive mount 후 working directory 이동 -- 런타임 초기화될때마다(코랩 킬 때마다)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8eRAsaDt_cH",
        "outputId": "92a4a0d9-6fd6-4111-e55d-c07568018cab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfzJh7PJxfcO",
        "outputId": "5a322f18-4966-43bc-8d10-9e79a0e9f2b7"
      },
      "source": [
        "cd /content/drive/My Drive/kfashion"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kfashion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoWYEItCaSm7"
      },
      "source": [
        "mmdetection 설치 -- 런타임 초기화될때마다(코랩 킬 때마다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cDrqcM1fgQK"
      },
      "source": [
        "!pip install openmim\n",
        "!mim install mmdet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv9pVyJheN_a"
      },
      "source": [
        "baseline code 가져오기 -- 1번만"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MmbdZtoeOJt"
      },
      "source": [
        "git clone 'https://github.com/dacon-ai/K-fashion-baseline.git'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxN6h_jdlHXe"
      },
      "source": [
        "Train/Test 폴더별 이미지 합치기 -- 1번만"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB95Rlu1LzcN"
      },
      "source": [
        "from shutil import copyfile\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def movefiles(filepath, movepath):\n",
        "    copyfile(filepath, movepath)\n",
        "    \n",
        "train_paths = glob(os.path.join('dataset', 'train', '*', '*.jpg'))\n",
        "test_paths = glob(os.path.join('dataset', 'test', '*', '*.jpg'))\n",
        "\n",
        "train_rename = ['dataset/train_all/' + train_path.split('/')[-1] for train_path in train_paths]\n",
        "test_rename = ['dataset/test_all/' + test_path.split('/')[-1] for test_path in test_paths]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9a46RwJlw-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ab2d57-d103-4128-a27c-af2d6b9c2f24"
      },
      "source": [
        "for i in tqdm(range((61339+14106), len(train_paths))):\n",
        "  copyfile(train_paths[i], train_rename[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 4842/20019 [24:02<1:12:18,  3.50it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfCJGcBmlwsl",
        "outputId": "381f54c9-3227-4bd9-8fba-8f5f969ba7ab"
      },
      "source": [
        "for i in tqdm(range(len(test_paths))): #완료\n",
        "  copyfile(test_paths[i], test_rename[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [39:16<00:00,  3.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyXwsoKjEb0c"
      },
      "source": [
        "Train/Validation 데이터셋 분할 -- 1번만\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykDR5RX8gB26"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "def split_dataset(input_json, input_csv, output_dir, val_ratio, random_seed):\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    with open(input_json) as json_reader:\n",
        "        dataset = json.load(json_reader)\n",
        "\n",
        "    images = dataset['images']\n",
        "    annotations = dataset['annotations']\n",
        "    categories = dataset['categories']\n",
        "\n",
        "    # file_name에 prefix 디렉토리까지 포함 (CocoDataset 클래스를 사용하는 경우)\n",
        "    for image in images:\n",
        "        image['file_name'] = '{}/{}'.format(image['file_name'][0], image['file_name'])\n",
        "\n",
        "    image_ids = [x.get('id') for x in images]\n",
        "    image_ids.sort()\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    num_val = int(len(image_ids) * val_ratio)\n",
        "    num_train = len(image_ids) - num_val\n",
        "\n",
        "    image_ids_val, image_ids_train = set(image_ids[:num_val]), set(image_ids[num_val:])\n",
        "\n",
        "    train_images = [x for x in images if x.get('id') in image_ids_train]\n",
        "    val_images = [x for x in images if x.get('id') in image_ids_val]\n",
        "    train_annotations = [x for x in annotations if x.get('image_id') in image_ids_train]\n",
        "    val_annotations = [x for x in annotations if x.get('image_id') in image_ids_val]\n",
        "\n",
        "    train_data = {\n",
        "        'images': train_images,\n",
        "        'annotations': train_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    val_data = {\n",
        "        'images': val_images,\n",
        "        'annotations': val_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    output_seed_dir = os.path.join(output_dir, f'seed{random_seed}')\n",
        "    os.makedirs(output_seed_dir, exist_ok=True)\n",
        "    output_train_json = os.path.join(output_seed_dir, 'train.json')\n",
        "    output_val_json = os.path.join(output_seed_dir, 'val.json')\n",
        "    output_train_csv = os.path.join(output_seed_dir, 'train.csv')\n",
        "    output_val_csv = os.path.join(output_seed_dir, 'val.csv')\n",
        "\n",
        "    print(f'write {output_train_json}')\n",
        "    with open(output_train_json, 'w') as train_writer:\n",
        "        json.dump(train_data, train_writer)\n",
        "\n",
        "    print(f'write {output_val_json}')\n",
        "    with open(output_val_json, 'w') as val_writer:\n",
        "        json.dump(val_data, val_writer)\n",
        "\n",
        "    print(f'write {output_train_csv}, {output_val_csv}')\n",
        "    with open(input_csv, 'r') as csv_reader, \\\n",
        "            open(output_train_csv, 'w') as train_writer, \\\n",
        "            open(output_val_csv, 'w') as val_writer:\n",
        "        train_writer.write('ImageId,EncodedPixels,Height,Width,CategoryId\\n')\n",
        "        val_writer.write('ImageId,EncodedPixels,Height,Width,CategoryId\\n')\n",
        "        for line in csv_reader:\n",
        "            if line.startswith('ImageId'): continue\n",
        "            image_id, encoded_pixels, height, width, category_id = line.strip().split(',')\n",
        "            image_id = int(image_id)\n",
        "            if image_id in image_ids_train:\n",
        "                train_writer.write(line)\n",
        "            elif image_id in image_ids_val:\n",
        "                val_writer.write(line)\n",
        "            else:\n",
        "                raise ValueError(f'unknown image_id: {image_id}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYsIyKS4kNU-",
        "outputId": "1aee04e1-aa70-4970-fc36-bf0c33d71d54"
      },
      "source": [
        "split_dataset(input_json='./dataset/train.json',\n",
        "              input_csv='./dataset/train.csv',\n",
        "              output_dir='./dataset/',\n",
        "              val_ratio=0.1,\n",
        "              random_seed=13)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "write ./dataset/seed13/train.json\n",
            "write ./dataset/seed13/val.json\n",
            "write ./dataset/seed13/train.csv, ./dataset/seed13/val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEWkFJ_PEHL8",
        "outputId": "fa7bc8d3-3d1d-46c9-9ebf-96f3bbabd681"
      },
      "source": [
        "train_data = json.load(open('./dataset/seed13/train.json'))\n",
        "\n",
        "print('training data')\n",
        "print(f'images: {len(train_data[\"images\"])}')\n",
        "print(f'annotations: {len(train_data[\"annotations\"])}')\n",
        "print(f'categories: {len(train_data[\"categories\"])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data\n",
            "images: 85909\n",
            "annotations: 101403\n",
            "categories: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibHQBmGjEIYs",
        "outputId": "8a4ab0e4-6035-458c-ddb4-a5591f0720a0"
      },
      "source": [
        "val_data = json.load(open('./dataset/seed13/val.json'))\n",
        "\n",
        "print('validation data')\n",
        "print(f'images: {len(val_data[\"images\"])}')\n",
        "print(f'annotations: {len(val_data[\"annotations\"])}')\n",
        "print(f'categories: {len(val_data[\"categories\"])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation data\n",
            "images: 9545\n",
            "annotations: 11265\n",
            "categories: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TIfIMWrOPEs"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-2zI2YTOQok",
        "outputId": "99725255-e0b4-4a61-c359-ad5267fa2a25"
      },
      "source": [
        "cd mmdetection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kfashion/mmdetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhQ4rer0QHIM"
      },
      "source": [
        "!python tools/train.py configs/_base_/default_runtime.py "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}